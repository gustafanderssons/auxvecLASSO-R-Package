survey_vars = survey_vars,
domain_vars = "stype",
diagnostics = c("weight_variation", "register_diagnostics", "survey_diagnostics"),
already_calibrated = FALSE
)
# Subset sample for speed
df <- apistrat[1:50, ]
# Add two binary register variables based on 'stype'
df$binary_register1 <- ifelse(df$stype == "E", 1, 0)  # elementary school indicator
df$binary_register2 <- ifelse(df$stype == "H", 1, 0)  # high school indicator
# Survey variables: use binary vars api99 and api00 converted to binary for test
df$api00_bin <- ifelse(df$api00 > median(df$api00), 1, 0)
df$api99_bin <- ifelse(df$api99 > median(df$api99), 1, 0)
survey_vars <- c("api00_bin", "api99_bin")
# Create survey design with stratification and weights
design <- svydesign(ids = ~1, strata = ~stype, weights = ~pw, data = df)
# Calibration formula only includes binary_register1 to avoid SE issues
calib_formula <- ~ binary_register1
# Population totals for calibration from full population data (apipop)
pop_totals <- c(
`(Intercept)` = nrow(apipop),
binary_register1 = sum(apipop$stype == "E")
)
# Register population means for both registers (overall and by domain)
register_pop_means <- list(
total = c(
binary_register1 = mean(ifelse(apipop$stype == "E", 1, 0)),
binary_register2 = mean(ifelse(apipop$stype == "H", 1, 0))
),
by_domain = aggregate(
cbind(
binary_register1 = ifelse(apipop$stype == "E", 1, 0),
binary_register2 = ifelse(apipop$stype == "H", 1, 0)
) ~ stype,
data = apipop,
FUN = mean
)
)
# Run the function with all diagnostics requested
result <- assess_aux_vector(
design = design,
df = df,
calibration_formula = calib_formula,
calibration_pop_totals = pop_totals,
register_vars = c("binary_register1", "binary_register2"),
register_pop_means = register_pop_means,
survey_vars = survey_vars,
domain_vars = "stype",
diagnostics = c("weight_variation", "register_diagnostics", "survey_diagnostics"),
already_calibrated = FALSE
)
result
View(result)
# Subset sample for speed
df <- apistrat[1:50, ]
# Add two binary register variables based on 'stype'
df$binary_register1 <- ifelse(df$stype == "E", 1, 0)  # elementary school indicator
df$binary_register2 <- ifelse(df$stype == "H", 1, 0)  # high school indicator
# Survey variables: binary versions of api00 and api99
df$api00_bin <- ifelse(df$api00 > median(df$api00), 1, 0)
df$api99_bin <- ifelse(df$api99 > median(df$api99), 1, 0)
survey_vars <- c("api00_bin", "api99_bin")
# Create survey design with stratification and weights
design <- svydesign(ids = ~1, strata = ~stype, weights = ~pw, data = df)
# Calibration formula uses 'enroll' only (numeric)
calib_formula <- ~ enroll
# Population totals for calibration from full population data (apipop)
pop_totals <- c(
`(Intercept)` = nrow(apipop),
enroll = sum(apipop$enroll)
)
# Register population means for both registers (overall and by domain)
register_pop_means <- list(
total = c(
binary_register1 = mean(ifelse(apipop$stype == "E", 1, 0)),
binary_register2 = mean(ifelse(apipop$stype == "H", 1, 0))
),
by_domain = aggregate(
cbind(
binary_register1 = ifelse(apipop$stype == "E", 1, 0),
binary_register2 = ifelse(apipop$stype == "H", 1, 0)
) ~ stype,
data = apipop,
FUN = mean
)
)
# Run the function with all diagnostics requested
result <- assess_aux_vector(
design = design,
df = df,
calibration_formula = calib_formula,
calibration_pop_totals = pop_totals,
register_vars = c("binary_register1", "binary_register2"),
register_pop_means = register_pop_means,
survey_vars = survey_vars,
domain_vars = "stype",
diagnostics = c("weight_variation", "register_diagnostics", "survey_diagnostics"),
already_calibrated = FALSE
)
data(api)
# Subset sample for speed
df <- apistrat[1:50, ]
# Add two binary register variables based on 'stype'
df$binary_register1 <- ifelse(df$stype == "E", 1, 0)  # elementary school indicator
df$binary_register2 <- ifelse(df$stype == "H", 1, 0)  # high school indicator
# Survey variables: binary versions of api00 and api99
df$api00_bin <- ifelse(df$api00 > median(df$api00), 1, 0)
df$api99_bin <- ifelse(df$api99 > median(df$api99), 1, 0)
survey_vars <- c("api00_bin", "api99_bin")
# Create survey design with stratification and weights
design <- svydesign(ids = ~1, strata = ~stype, weights = ~pw, data = df)
# Calibration formula uses 'enroll' only (numeric)
calib_formula <- ~ enroll
# Population totals for calibration from full population data (apipop)
pop_totals <- c(
`(Intercept)` = nrow(apipop),
enroll = sum(apipop$enroll)
)
# Register population means for both registers (overall and by domain)
register_pop_means <- list(
total = c(
binary_register1 = mean(ifelse(apipop$stype == "E", 1, 0)),
binary_register2 = mean(ifelse(apipop$stype == "H", 1, 0))
),
by_domain = aggregate(
cbind(
binary_register1 = ifelse(apipop$stype == "E", 1, 0),
binary_register2 = ifelse(apipop$stype == "H", 1, 0)
) ~ stype,
data = apipop,
FUN = mean
)
)
# Run the function with all diagnostics requested
result <- assess_aux_vector(
design = design,
df = df,
calibration_formula = calib_formula,
calibration_pop_totals = pop_totals,
register_vars = c("binary_register1", "binary_register2"),
register_pop_means = register_pop_means,
survey_vars = survey_vars,
domain_vars = "stype",
diagnostics = c("weight_variation", "register_diagnostics", "survey_diagnostics"),
already_calibrated = FALSE
)
summary(df$enroll)
any(is.na(df$enroll))
any(df$enroll == 0)
length(pop_totals)
names(pop_totals)
model.matrix(calib_formula, data = df)
cal <- try(calibrate(design, formula = calib_formula, population = pop_totals))
if (inherits(cal, "try-error")) print(cal)
View(cal)
try(calibrate(design, formula = calib_formula, population = pop_totals))
if (inherits(cal, "try-error")) print(cal)
View(cal)
cal
View(design)
calibrate(design, formula = calib_formula, population = pop_totals)
cal <- calibrate(design, formula = calib_formula, population = pop_totals)
weights(cal)
summary(weights(design))
# Subset sample for speed
df <- apistrat[1:50, ]
# Add two binary register variables based on 'stype'
df$binary_register1 <- ifelse(df$stype == "E", 1, 0)  # elementary school indicator
df$binary_register2 <- ifelse(df$stype == "H", 1, 0)  # high school indicator
# Survey variables: binary versions of api00 and api99
df$api00_bin <- ifelse(df$api00 > median(df$api00), 1, 0)
df$api99_bin <- ifelse(df$api99 > median(df$api99), 1, 0)
survey_vars <- c("api00_bin", "api99_bin")
# Create categorical enroll variable by binning
df$enroll_cat <- cut(df$enroll, breaks = c(-Inf, 200, 500, Inf),
labels = c("small", "medium", "large"))
# Do the same for the population
apipop$enroll_cat <- cut(apipop$enroll, breaks = c(-Inf, 200, 500, Inf),
labels = c("small", "medium", "large"))
# Create survey design with stratification and weights
design <- svydesign(ids = ~1, strata = ~stype, weights = ~pw, data = df)
# Calibration formula using enroll_cat categorical variable
calib_formula <- ~ enroll_cat
# Population totals for calibration from full population data
X_pop <- model.matrix(calib_formula, data = apipop)
pop_totals <- colSums(X_pop)
# Register population means for both registers (overall and by domain)
register_pop_means <- list(
total = c(
binary_register1 = mean(ifelse(apipop$stype == "E", 1, 0)),
binary_register2 = mean(ifelse(apipop$stype == "H", 1, 0))
),
by_domain = aggregate(
cbind(
binary_register1 = ifelse(apipop$stype == "E", 1, 0),
binary_register2 = ifelse(apipop$stype == "H", 1, 0)
) ~ stype,
data = apipop,
FUN = mean
)
)
# Run the function with all diagnostics requested
result <- assess_aux_vector(
design = design,
df = df,
calibration_formula = calib_formula,
calibration_pop_totals = pop_totals,
register_vars = c("binary_register1", "binary_register2"),
register_pop_means = register_pop_means,
survey_vars = survey_vars,
domain_vars = "stype",
diagnostics = c("weight_variation", "register_diagnostics", "survey_diagnostics"),
already_calibrated = FALSE
)
result
View(result)
# Subset sample for speed
df <- apistrat[1:50, ]
# Create two independent binary register variables unrelated to 'stype'
set.seed(123)  # for reproducibility
df$binary_register1 <- rbinom(nrow(df), size = 1, prob = 0.5)
df$binary_register2 <- rbinom(nrow(df), size = 1, prob = 0.5)
# Survey variables: binary versions of api00 and api99
df$api00_bin <- ifelse(df$api00 > median(df$api00), 1, 0)
df$api99_bin <- ifelse(df$api99 > median(df$api99), 1, 0)
survey_vars <- c("api00_bin", "api99_bin")
# Create categorical enroll variable by binning
df$enroll_cat <- cut(df$enroll, breaks = c(-Inf, 200, 500, Inf),
labels = c("small", "medium", "large"))
# Do the same for the population
apipop$enroll_cat <- cut(apipop$enroll, breaks = c(-Inf, 200, 500, Inf),
labels = c("small", "medium", "large"))
# Create independent register variables in population as well (same probabilities)
set.seed(123)
apipop$binary_register1 <- rbinom(nrow(apipop), size = 1, prob = 0.5)
apipop$binary_register2 <- rbinom(nrow(apipop), size = 1, prob = 0.5)
# Create survey design with stratification and weights
design <- svydesign(ids = ~1, strata = ~stype, weights = ~pw, data = df)
# Calibration formula using enroll_cat categorical variable
calib_formula <- ~ enroll_cat
# Population totals for calibration from full population data
X_pop <- model.matrix(calib_formula, data = apipop)
pop_totals <- colSums(X_pop)
# Register population means for both registers (overall and by domain)
register_pop_means <- list(
total = c(
binary_register1 = mean(apipop$binary_register1),
binary_register2 = mean(apipop$binary_register2)
),
by_domain = aggregate(
cbind(binary_register1, binary_register2) ~ stype,
data = apipop,
FUN = mean
)
)
# Run the function with all diagnostics requested
result <- assess_aux_vector(
design = design,
df = df,
calibration_formula = calib_formula,
calibration_pop_totals = pop_totals,
register_vars = c("binary_register1", "binary_register2"),
register_pop_means = register_pop_means,
survey_vars = survey_vars,
domain_vars = "stype",
diagnostics = c("weight_variation", "register_diagnostics", "survey_diagnostics"),
already_calibrated = FALSE
)
View(result)
str(result)
reult
result
result
devtools::load_all()
data(api)
# Subset sample for speed
df <- apistrat[1:50, ]
# Create two independent binary register variables unrelated to 'stype'
set.seed(123)  # for reproducibility
df$binary_register1 <- rbinom(nrow(df), size = 1, prob = 0.5)
df$binary_register2 <- rbinom(nrow(df), size = 1, prob = 0.5)
# Survey variables: binary versions of api00 and api99
df$api00_bin <- ifelse(df$api00 > median(df$api00), 1, 0)
df$api99_bin <- ifelse(df$api99 > median(df$api99), 1, 0)
survey_vars <- c("api00_bin", "api99_bin")
# Create categorical enroll variable by binning
df$enroll_cat <- cut(df$enroll, breaks = c(-Inf, 200, 500, Inf),
labels = c("small", "medium", "large"))
# Do the same for the population
apipop$enroll_cat <- cut(apipop$enroll, breaks = c(-Inf, 200, 500, Inf),
labels = c("small", "medium", "large"))
# Create independent register variables in population as well (same probabilities)
set.seed(123)
apipop$binary_register1 <- rbinom(nrow(apipop), size = 1, prob = 0.5)
apipop$binary_register2 <- rbinom(nrow(apipop), size = 1, prob = 0.5)
# Create survey design with stratification and weights
design <- svydesign(ids = ~1, strata = ~stype, weights = ~pw, data = df)
# Calibration formula using enroll_cat categorical variable
calib_formula <- ~ enroll_cat
# Population totals for calibration from full population data
X_pop <- model.matrix(calib_formula, data = apipop)
pop_totals <- colSums(X_pop)
# Register population means for both registers (overall and by domain)
register_pop_means <- list(
total = c(
binary_register1 = mean(apipop$binary_register1),
binary_register2 = mean(apipop$binary_register2)
),
by_domain = aggregate(
cbind(binary_register1, binary_register2) ~ stype,
data = apipop,
FUN = mean
)
)
# Run the function with all diagnostics requested
result <- assess_aux_vector(
design = design,
df = df,
calibration_formula = calib_formula,
calibration_pop_totals = pop_totals,
register_vars = c("binary_register1", "binary_register2"),
register_pop_means = register_pop_means,
survey_vars = survey_vars,
domain_vars = "stype",
diagnostics = c("weight_variation", "register_diagnostics", "survey_diagnostics"),
already_calibrated = FALSE
)
result
devtools::document()
devtools::document()
devtools::test()
test_that("factor auxiliary variables are properly converted to dummies", {
df <- data.frame(
y = factor(sample(c("A", "B"), 100, replace = TRUE)),
group = factor(sample(c("G1", "G2", "G3"), 100, replace = TRUE))
)
formula_str <- "~ group -1"
X <- model.matrix(as.formula(formula_str), data = df)
expect_true(any(grepl("^group", colnames(X))))
})
result$register_diagnostics$total
devtools::test()
usethis::use_r("create_peanlty_factors_vector.R")
usethis::use_r("setup_parallel.R")
usethis::use_r("extract_coefs.R")
usethis::use_r("fit_outcome.R")
devtools::load_all()
devtools::test()
devtools::test()
usethis::use_r("message_verbose.R")
devtools::test()
devtools::test()
devtools::test()
devtools::test()
usethis::use_test("message_verbose.R")
usethis::use_test("fit_outcome.R")
usethis::use_test("extract_coefs.R")
usethis::use_test("setup_parallel.R")
usethis::use_test("create_penalty_factors_vector.R")
devtools::load_all()
devtools::test()
test_that("penalty factors default to 1 when must_have_vars is NULL or empty", {
colnames_X <- c("age", "sex", "bmi")
result1 <- create_penalty_factors(colnames_X, NULL)
expect_equal(unname(result1$penalty_factors), rep(1, length(colnames_X)))
expect_equal(unname(result1$must_have_idx), integer(0))
result2 <- create_penalty_factors(colnames_X, character(0))
expect_equalunname((result2$penalty_factors), rep(1, length(colnames_X)))
expect_equal(unname(result2$must_have_idx), integer(0))
})
test_that("penalty factors default to 1 when must_have_vars is NULL or empty", {
colnames_X <- c("age", "sex", "bmi")
result1 <- create_penalty_factors(colnames_X, NULL)
expect_equal(unname(result1$penalty_factors), rep(1, length(colnames_X)))
expect_equal(unname(result1$must_have_idx), integer(0))
result2 <- create_penalty_factors(colnames_X, character(0))
expect_equal(unname(result2$penalty_factors), rep(1, length(colnames_X)))
expect_equal(unname(result2$must_have_idx), integer(0))
})
test_that("penalty factors set to 0 for exact variable matches", {
colnames_X <- c("age", "sex", "bmi")
must_have_vars <- c("sex")
result <- create_penalty_factors(colnames_X, must_have_vars)
expect_equal(unname(result$must_have_idx), 2)
expect_equal(unname(result$penalty_factors["sex"]), 0)
expect_equal(unname(result$penalty_factors[c("age", "bmi")]), c(1,1))
expect_named(result$penalty_factors, colnames_X)
})
test_that("penalty factors set to 0 for variables with matching prefixes", {
colnames_X <- c("age", "sex_M", "sex_F", "bmi")
must_have_vars <- c("sex")
result <- create_penalty_factors(colnames_X, must_have_vars)
expect_equal(sort(result$must_have_idx), c(2, 3))
expect_true(all(result$penalty_factors[c("sex_M", "sex_F")] == 0))
expect_true(all(result$penalty_factors[c("age", "bmi")] == 1))
})
test_that("handles multiple must_have_vars with overlapping matches", {
colnames_X <- c("age", "sex_M", "sex_F", "bmi", "weight")
must_have_vars <- c("sex", "age")
result <- create_penalty_factors(colnames_X, must_have_vars)
expect_equal(sort(result$must_have_idx), c(1, 2, 3))
expect_true(all(result$penalty_factors[c("age", "sex_M", "sex_F")] == 0))
expect_true(all(result$penalty_factors[c("bmi", "weight")] == 1))
})
test_that("returns named penalty_factors vector matching colnames_X", {
colnames_X <- c("var1", "var2", "var3")
must_have_vars <- c("var")
result <- create_penalty_factors(colnames_X, must_have_vars)
expect_named(result$penalty_factors, colnames_X)
expect_length(result$penalty_factors, length(colnames_X))
})
test_that("goodness_of_fit contains expected metrics for binary outcome", {
set.seed(123)
df <- data.frame(
y = factor(sample(c(0, 1), 50, TRUE)),
x1 = rnorm(50), x2 = rnorm(50)
)
res <- select_auxiliary_variables_lasso_cv(
df = df,
outcome_vars = "y",
auxiliary_vars = c("x1", "x2"),
nfolds = 3,
verbose = FALSE
)
gof <- res$goodness_of_fit$y
expect_named(gof, c("cross_validated", "full_data"))
expect_named(gof$cross_validated, c("cv_error", "cv_error_sd"))
expect_type(gof$cross_validated$cv_error, "double")
expect_type(gof$cross_validated$cv_error_sd, "double")
expect_named(gof$full_data, c("deviance_explained", "auc", "accuracy", "brier_score", "abs_coefs", "raw_coefs"))
expect_gte(gof$full_data$accuracy, 0)
expect_lte(gof$full_data$accuracy, 1)
expect_gte(gof$full_data$brier_score, 0)
expect_lte(gof$full_data$brier_score, 1)
})
devtools::test()
devtools::test()
test_that("extract_coefs returns correct abs and raw coefs for binomial family", {
coefs_matrix <- matrix(c(1, 0.5, -0.2), ncol = 1,
dimnames = list(c("(Intercept)", "x1", "x2"), NULL))
mock_cv_fit <- structure(list(), class = "cv.glmnet")
local({
coef <- function(object, s, ...) {
expect_equal(s, "lambda.min")
coefs_matrix
}
res <- extract_coefs(mock_cv_fit, family = "binomial")
expect_true(is.list(res))
expect_named(res, c("abs_coefs", "raw_coefs"))
expect_false("(Intercept)" %in% names(res$abs_coefs))
expect_false("(Intercept)" %in% names(res$raw_coefs))
expect_equal(res$abs_coefs["x1"], abs(0.5))
expect_equal(res$raw_coefs["x2"], -0.2)
})
})
test_that("extract_coefs returns correct abs and raw coefs for multinomial family", {
coefs_class1 <- matrix(c(0.1, 0.5, 0), ncol = 1,
dimnames = list(c("(Intercept)", "x1", "x2"), NULL))
coefs_class2 <- matrix(c(-0.1, 0, 0.3), ncol = 1,
dimnames = list(c("(Intercept)", "x1", "x2"), NULL))
coefs_list <- list(class1 = coefs_class1, class2 = coefs_class2)
mock_cv_fit <- structure(list(), class = "cv.glmnet")
local({
coef <- function(object, s, ...) {
expect_equal(s, "lambda.min")
coefs_list
}
res <- extract_coefs(mock_cv_fit, family = "multinomial")
expect_true(is.list(res))
expect_named(res, c("abs_coefs", "raw_coefs"))
expect_true(all(c("x1", "x2", "(Intercept)") %in% names(res$abs_coefs)))
expect_equal(res$abs_coefs["x1"], mean(abs(c(0.5, 0))))
expect_equal(res$raw_coefs["x2"], mean(c(0, 0.3)))
})
})
test_that("extract_coefs handles missing variables gracefully in multinomial", {
coefs_class1 <- matrix(c(0.1, 0.5), ncol = 1,
dimnames = list(c("(Intercept)", "x1"), NULL))
coefs_class2 <- matrix(c(-0.1, 0.3), ncol = 1,
dimnames = list(c("(Intercept)", "x2"), NULL))
coefs_list <- list(class1 = coefs_class1, class2 = coefs_class2)
mock_cv_fit <- structure(list(), class = "cv.glmnet")
local({
coef <- function(object, s, ...) {
expect_equal(s, "lambda.min")
coefs_list
}
res <- extract_coefs(mock_cv_fit, family = "multinomial")
expect_named(res$abs_coefs, c("(Intercept)", "x1", "x2"))
expect_equal(res$abs_coefs["x1"], mean(abs(c(0.5, 0))))
expect_equal(res$raw_coefs["x2"], mean(c(0, 0.3)))
})
})
devtools::test()
library(covr)
coverage <- package_coverage()
library(covr)
1+1
coverage <- covr::package_coverage()
coverage <- covr::package_coverage(path = ".", type = "tests")
devtools::load_all()
styler::style_pkg()
styler::style_pkg()
devtools::check()
devtools::check()
devtools::check()
usethis::use_vignette("intro-to-auxvecLASSO")
devtools::build_vignettes()
devtools::check()
devtools::document()
devtools::check()
devtools::check()
